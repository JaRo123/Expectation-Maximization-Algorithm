# EM with two distributions which aren't similar
options(digits = 4) # to control the number of decimal digits in print output
library("tigerstats")  # Ask R to use the tigerstats package
set.seed(123)
tau_true <- 0.60 # A biesed coin that comes up heads 60% of the time
x <- y <- rep(0,500) # replicates the values in x for 500 times
for( i in 1:500 ) {
  if( runif(1) < tau_true ) {
    x[i] <- rnorm(1, mean=0, sd=2) # If it is head, we draw from a Normal distribution mean 0, sd 2 
    y[i] <- "heads"
  } else {
    x[i] <- rnorm(1, mean=8, sd=0.5) # If it is xtail, we draw from a Normal distribution mean 8, sd 0.5
    y[i] <- "tails"
  }
}

densityplot( ~x, 
             par.settings = list(
               plot.symbol = list(
                 col=as.factor(y)
               )
             )
)

print( x[1] )
dnorm( x[1], mean=0 ) #dnorm is a function for normal distribution
dnorm( x[1], mean=8 )
tau_1 <- 0.75 ## our initial believed proportion from dist. 1, chosen arbitrarily
tau_2 <- 0.75 ## our initial believed proportion from dist. 2, chosen arbitrarily

T_1 <- tau_1 * dnorm( x[1], mean=0 )
T_2 <- tau_2 * dnorm( x[1], mean=8 )

print( T_1 )
print( T_2 )
T_1 / (T_1 + T_2)
T_1 <- tau_1 * dnorm( x, mean=0 )
T_2 <- tau_2 * dnorm( x, mean=8 )

head( T_1 / (T_1 + T_2) )
P_1 <- T_1 / (T_1 + T_2)
P_2 <- T_2 / (T_1 + T_2)

mu_1 <- sum( P_1 * x ) / sum(P_1)
mu_2 <- sum( P_2 * x ) / sum(P_2)

c(mu_1, mu_2)

## set the initial guesses for the distribution parameters
mu_1 <- 0
mu_2 <- 1

## as well as the latent variable parameters
tau_1 <- 0.5
tau_2 <- 0.5

for( i in 1:12 ) {
  
  ## Given the observed data, as well as the distribution parameters,
  ## what are the latent variables?
  
  T_1 <- tau_1 * dnorm( x, mu_1 )
  T_2 <- tau_2 * dnorm( x, mu_2 )
  
  P_1 <- T_1 / (T_1 + T_2)
  P_2 <- T_2 / (T_1 + T_2) ## note: P_2 = 1 - P_1
  
  tau_1 <- mean(P_1)
  tau_2 <- mean(P_2)
  
  ## Given the observed data, as well as the latent variables,
  ## what are the population parameters?
  
  mu_1 <- sum( P_1 * x ) / sum(P_1)
  mu_2 <- sum( P_2 * x ) / sum(P_2)
  sd_1 <- (sum(P_1*(x-mu_1)^2)/ sum(P_1))^0.5 # it is sigma power 2
  sd_2 <- (sum(P_2*(x-mu_2)^2)/ sum(P_2))^0.5 # it is sigma power 2
  ## print the current estimates
    print( c(mu_1, mu_2, sd_1, sd_2, mean(P_1), mean(P_2)) ) 
  
}
install.packages("mixtools")
library("mixtools")
myEM <- normalmixEM( x, mu = c(0,1), sigma=c(0.5,1))
myEM$mu ## the means of the two distributions
myEM$lambda ## the mixing probabilities
myEM$sigma ## the mixing probabilities

